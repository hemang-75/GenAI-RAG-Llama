# ğŸš€ GenAI-RAG-Llama  

### ğŸ“„ Document QnA using Llama 3  

This project leverages **Llama 3.2** and **Streamlit** to create a fully **local** Document Question Answering (QnA) app. Users can upload documents and perform **QnA** directly on them.  

---

## ğŸ“¥ Installation and Setup  

### 1ï¸âƒ£ **Setup Ollama**  
First, install **Ollama** and pull the **Llama 3.2** model:  

```bash
# Install Ollama on Linux  
curl -fsSL https://ollama.com/install.sh | sh

# Pull the Llama 3.2 model  
ollama run llama3.2
```

### 2ï¸âƒ£ **Install Dependencies**  
Ensure you have **Python 3.11 or later** installed, then install the required packages:  

```bash
pip install -r requirements.txt
```

### 3ï¸âƒ£ **Launch the Streamlit App**  
Once everything is set up, run the following command to start the application:  

```bash
streamlit run rag_ollama.py
```

---

## ğŸ–¥ï¸ Application Interface  
This is how the application looks when launched:  

<p align="center">
  <img src="images/img_1.png" alt="App Screenshot 1" width="600">
</p>

---

## ğŸ“„ Uploading a Document  
Once a document is uploaded, the UI updates to display the document processing section:  

<p align="center">
  <img src="images/img_2.png" alt="App Screenshot 2" width="600">
</p>

---

## â“ Asking Questions & Getting Answers  
After uploading a document, users can ask questions, and the app will generate relevant answers:  

<p align="center">
  <img src="images/img_3.png" alt="App Screenshot 3" width="600">
</p>

---

## ğŸ›  Features  
- âœ” Runs **completely locally** (no API required)  
- âœ” Uses **Llama 3.2** for Document QnA  
- âœ” Simple and interactive **Streamlit UI**  
- âœ” **Fast processing** and easy to use  

---

## ğŸ“ License  
This project is open-source and available under the **GNU General Public License**.

---

## ğŸ¤ Contributing  
If youâ€™d like to contribute, feel free to fork the repository, create a new branch, and submit a pull request!  

---

### â­ If you find this project useful, consider **starring** the repository on GitHub!  
